{"cells":[{"cell_type":"markdown","source":["# VectorDB_Embedding１：ダイレクトにIndexから文書を選びベクトル化"],"metadata":{"id":"JnvUqiSEZFkS"}},{"cell_type":"code","source":["!pip uninstall -y openai\n","!pip install openai==0.28.0\n","\n","!pip install tiktoken\n","!pip install python-dotenv\n","!pip install pinecone==6.0.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Dcrstdii4TM","outputId":"ba85eb81-68bf-4cef-c3b3-595491a82081","executionInfo":{"status":"ok","timestamp":1742973092853,"user_tz":-540,"elapsed":13984,"user":{"displayName":"岸山直人","userId":"10402154690479700902"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: openai 1.68.2\n","Uninstalling openai-1.68.2:\n","  Successfully uninstalled openai-1.68.2\n","Collecting openai==0.28.0\n","  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (4.67.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (3.11.14)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (2025.1.31)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (6.2.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.18.3)\n","Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: openai\n","Successfully installed openai-0.28.0\n","Collecting tiktoken\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n","Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.9.0\n","Collecting python-dotenv\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.1.0\n","Collecting pinecone==6.0.1\n","  Downloading pinecone-6.0.1-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone==6.0.1) (2025.1.31)\n","Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone==6.0.1)\n","  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone==6.0.1) (2.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone==6.0.1) (4.12.2)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone==6.0.1) (2.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone==6.0.1) (1.17.0)\n","Downloading pinecone-6.0.1-py3-none-any.whl (421 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.4/421.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n","Installing collected packages: pinecone-plugin-interface, pinecone\n","Successfully installed pinecone-6.0.1 pinecone-plugin-interface-0.0.7\n"]}]},{"cell_type":"code","source":["import requests\n","import re\n","import os\n","import csv\n","import time  # ★ sleep用\n","import pandas as pd\n","from urllib.parse import urlsplit\n","from bs4 import BeautifulSoup\n","\n","import openai\n","import tiktoken\n","from dotenv import load_dotenv\n","from pinecone import Pinecone\n","from pinecone import NotFoundException  # ← 例外ハンドリング用\n","\n","############################\n","# 1) APIキー読み込み\n","############################\n","def load_api_keys(txt_filepath=\"api_keys.txt\"):\n","    if not os.path.exists(txt_filepath):\n","        raise FileNotFoundError(f\"APIキーのファイルが見つかりません: {txt_filepath}\")\n","\n","    # BOM 付き UTF-8 でも読めるように encoding=\"utf-8\"\n","    with open(txt_filepath, \"r\", encoding=\"utf-8\") as f:\n","        lines = f.readlines()\n","    for line in lines:\n","        line = line.strip()\n","        if not line or line.startswith(\"#\"):\n","            continue\n","        if \"=\" in line:\n","            k, v = line.split(\"=\", 1)\n","            os.environ[k.strip()] = v.strip()\n","\n","load_api_keys(\"api_keys.txt\")\n","\n","PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\", \"\")\n","OPENAI_API_KEY   = os.getenv(\"OPENAI_API_KEY\", \"\")\n","openai.api_key   = OPENAI_API_KEY\n","\n","INDEX_NAME = \"concur-index\"\n","NAMESPACE  = \"demo-html\"\n","\n","############################\n","# 2) Pinecone 初期化\n","############################\n","pc = Pinecone(api_key=PINECONE_API_KEY)\n","index = pc.Index(INDEX_NAME)\n","\n","# ▼▼ ここで全部消していた処理をコメントアウト ▼▼\n","# try:\n","#     index.delete(deleteAll=True, namespace=NAMESPACE)\n","#     print(f\"[INFO] Deleted all vectors in namespace '{NAMESPACE}'.\")\n","# except NotFoundException:\n","#     print(f\"[WARN] '{NAMESPACE}' namespace not found. (No problem, skipping.)\")\n","\n","stats = index.describe_index_stats()\n","ns_info = stats.get(\"namespaces\", {})\n","if NAMESPACE in ns_info:\n","    print(f\"[INFO] namespace '{NAMESPACE}' 既に存在: vector_count={ns_info[NAMESPACE]['vector_count']}\")\n","else:\n","    print(f\"[INFO] namespace '{NAMESPACE}' はまだ存在しません。\")\n","\n","\n","############################\n","# 3) indexページをパース (HTMLスクレイプ)\n","############################\n","def parse_index_page(index_url):\n","    resp = requests.get(index_url)\n","    resp.raise_for_status()\n","    soup = BeautifulSoup(resp.text, \"html.parser\")\n","\n","    result_list = []\n","    table = soup.find(\"table\")\n","    if not table:\n","        print(\"[WARN] テーブルが見つかりません:\", index_url)\n","        return result_list\n","\n","    for row in table.find_all(\"tr\"):\n","        cols = row.find_all(\"td\")\n","        if len(cols) < 4:\n","            continue\n","        guide_en = cols[0].get_text(strip=True)\n","        guide_jp = cols[1].get_text(strip=True)\n","        base_url = cols[3].get_text(strip=True)\n","        result_list.append({\n","            \"GuideNameEn\": guide_en,\n","            \"GuideNameJp\": guide_jp,\n","            \"BaseURL\": base_url\n","        })\n","    return result_list\n","\n","\n","############################\n","# 4) mapping_DB.csv ロード\n","############################\n","def load_mapping_db(csv_path=\"mapping_DB.csv\"):\n","    if not os.path.exists(csv_path):\n","        raise FileNotFoundError(f\"[ERROR] mapping_DB.csv が見つかりません: {csv_path}\")\n","\n","    rows = []\n","    with open(csv_path, \"r\", encoding=\"utf-8-sig\") as f:\n","        reader = csv.DictReader(f, delimiter=\",\")\n","        for row in reader:\n","            rows.append(row)\n","    return rows\n","\n","\n","############################\n","# 5) HTMLソース取得\n","############################\n","def fetch_html(url):\n","    resp = requests.get(url)\n","    resp.raise_for_status()\n","    return resp.text\n","\n","############################\n","# 6) アンカーoffset検索\n","############################\n","def find_anchor_offset(html_src, anchor_id):\n","    pattern = re.compile(\n","        rf'<a[^>]+(?:id|name)\\s*=\\s*[\"\\']{re.escape(anchor_id)}[\"\\']',\n","        re.IGNORECASE\n","    )\n","    m = pattern.search(html_src)\n","    if m:\n","        return m.start()\n","    return -1\n","\n","############################\n","# 7) chunking & embedding\n","############################\n","def get_embedding(text: str, model=\"text-embedding-ada-002\"):\n","    resp = openai.Embedding.create(model=model, input=text)\n","    return resp[\"data\"][0][\"embedding\"]\n","\n","def chunk_text(text: str, chunk_size=2000):\n","    chunks = []\n","    start = 0\n","    length = len(text)\n","    while start < length:\n","        end = min(start + chunk_size, length)\n","        chunks.append(text[start:end])\n","        start = end\n","    return chunks\n","\n","\n","############################\n","# メインフロー\n","############################\n","def main():\n","    # 1) indexページをスクレイプしてガイド一覧を取得\n","    index_url = \"https://la-concur-helper.github.io/concur-docs/index.htm\"\n","    docs = parse_index_page(index_url)\n","    if not docs:\n","        print(\"[ERROR] indexページからガイド情報が取得できませんでした。\")\n","        return\n","\n","    print(\"\\n=== ガイド一覧 ===\")\n","    for i, d in enumerate(docs, start=1):\n","        print(f\"{i}. {d['GuideNameEn']} / {d['GuideNameJp']} => {d['BaseURL']}\")\n","\n","    sel = input(\"\\nどのガイドを処理しますか？(番号): \").strip()\n","    if not sel.isdigit():\n","        print(\"キャンセル\")\n","        return\n","    idx = int(sel)\n","    if idx < 1 or idx > len(docs):\n","        print(\"[ERROR] 選択が範囲外。終了。\")\n","        return\n","\n","    chosen = docs[idx-1]\n","    base_url = chosen[\"BaseURL\"]\n","    guide_en = chosen[\"GuideNameEn\"]\n","    guide_jp = chosen[\"GuideNameJp\"]\n","\n","    # e.g. \"Exp_SG_Account_Codes-jp.html\" -> \"Exp_SG_Account_Codes-jp.docx\"\n","    fname = os.path.basename(urlsplit(base_url).path)\n","    doc_name = re.sub(r\"\\.html?$\", \".docx\", fname, flags=re.IGNORECASE)\n","\n","    print(f\"\\n選択されたガイド => doc_name={doc_name}, base_url={base_url}\")\n","\n","    # 2) mapping_DB.csv をロード\n","    mapping_rows = load_mapping_db(\"mapping_DB.csv\")\n","    if not mapping_rows:\n","        print(\"[WARN] mapping_DB.csv から行が読み込めませんでした。\")\n","        return\n","\n","    # doc_name 一致行を抽出\n","    doc_rows = [r for r in mapping_rows if r.get(\"DocName\",\"\") == doc_name]\n","    if not doc_rows:\n","        print(f\"[WARN] DocName='{doc_name}' の行がmapping_DB.csvにありません。終了。\")\n","        return\n","\n","    # 3) HTMLを取得\n","    html_src = fetch_html(base_url)\n","    print(f\"[INFO] HTMLソース取得: 長さ={len(html_src)}\")\n","\n","    # 4) doc_rows を PageNumber + AnchorID でソート\n","    def sort_key(row):\n","        p = 999999\n","        if row[\"PageNumber\"].isdigit():\n","            p = int(row[\"PageNumber\"])\n","        return (p, row[\"AnchorID\"])\n","    sorted_rows = sorted(doc_rows, key=sort_key)\n","\n","    # 5) offset計算\n","    offsets = []\n","    for row in sorted_rows:\n","        anchor_id = row[\"AnchorID\"]\n","        off = find_anchor_offset(html_src, anchor_id)\n","        offsets.append({ \"row\": row, \"offset\": off })\n","\n","    ############################\n","    # ▼▼ バッチアップサート ▼▼\n","    ############################\n","\n","    BATCH_SIZE = 100\n","    vectors_buffer = []\n","    doc_id_counter = 0\n","\n","    def flush_upsert_buffer():\n","        nonlocal vectors_buffer\n","        if not vectors_buffer:\n","            return\n","        print(f\"[BATCH UPSERT] {len(vectors_buffer)} vectors ...\")\n","        resp = index.upsert(vectors=vectors_buffer, namespace=NAMESPACE)\n","        print(\"[BATCH RESP]:\", resp)\n","        vectors_buffer = []\n","        time.sleep(1)\n","\n","    # offset[i]~offset[i+1] で区間抽出 => chunk化 => embedding => upsert\n","    for i in range(len(offsets)):\n","        cur = offsets[i]\n","        row  = cur[\"row\"]\n","        off_i = cur[\"offset\"]\n","        if off_i < 0:\n","            off_i = 0\n","\n","        if i < len(offsets)-1:\n","            off_j = offsets[i+1][\"offset\"]\n","            if off_j < 0:\n","                off_j = len(html_src)\n","        else:\n","            off_j = len(html_src)\n","\n","        if off_j < off_i:\n","            off_j = off_i\n","\n","        raw_segment = html_src[off_i:off_j]\n","        text_str = re.sub(r\"<[^>]+>\", \"\", raw_segment)\n","        text_str = re.sub(r\"\\s+\", \" \", text_str).strip()\n","        if not text_str:\n","            continue\n","\n","        doc_name_val = row[\"DocName\"]\n","        guide_jp_val = row[\"GuideNameJp\"]\n","        sec1         = row[\"SectionTitle1\"]\n","        sec2         = row[\"SectionTitle2\"]\n","        anchor_val   = row[\"AnchorID\"]\n","        link_val     = row[\"FullLink\"]\n","\n","        # セクションタイトルと本文の間に改行\n","        combined_text = f\"{sec1}\\n{sec2}\\n\\n{text_str}\"\n","\n","        chunk_list = chunk_text(combined_text, chunk_size=2000)\n","\n","        for chunk_str_data in chunk_list:\n","            doc_id_counter += 1\n","            chunk_id = f\"{doc_name_val}_chunk{doc_id_counter}\"\n","\n","            emb = get_embedding(chunk_str_data)\n","            meta = {\n","                \"DocName\": doc_name_val,\n","                \"GuideNameJp\": guide_jp_val,\n","                \"SectionTitle1\": sec1,\n","                \"SectionTitle2\": sec2,\n","                \"AnchorID\": anchor_val,\n","                \"FullLink\": link_val,\n","                \"chunk_text\": chunk_str_data\n","            }\n","\n","            vectors_buffer.append({\n","                \"id\": chunk_id,\n","                \"values\": emb,\n","                \"metadata\": meta\n","            })\n","\n","            if len(vectors_buffer) >= BATCH_SIZE:\n","                flush_upsert_buffer()\n","\n","    # バッファに残ったデータを最後にアップサート\n","    flush_upsert_buffer()\n","    print(\"[INFO] 全アップサート完了\")\n","\n","    # テスト検索\n","    test_query = \"ConcurのAPIでレシート登録したい\"\n","    print(f\"\\n[INFO] テスト検索: {test_query}\")\n","    q_emb = get_embedding(test_query)\n","    sr = index.query(\n","        vector=q_emb,\n","        top_k=3,\n","        include_metadata=True,\n","        namespace=NAMESPACE\n","    )\n","    for match in sr.matches:\n","        md = match.metadata\n","        print(f\"- ID={match.id}, Score={match.score}\")\n","        print(\"  SectionTitle2:\", md.get(\"SectionTitle2\"))\n","        print(\"  FullLink:\", md.get(\"FullLink\"))\n","        print(\"  chunk_text:\", md.get(\"chunk_text\",\"\")[:80], \"...\\n\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Og1EzEUGp4I1","outputId":"6d6d9872-a33b-4ddd-870c-d162665cb3fe","executionInfo":{"status":"ok","timestamp":1742524898405,"user_tz":-540,"elapsed":11272,"user":{"displayName":"岸山直人","userId":"10402154690479700902"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] namespace 'demo-html' 既に存在: vector_count=2251\n","\n","=== ガイド一覧 ===\n","1. Guide Name / ガイド名 => URL\n","2. Account Codes / 勘定科目コード(2017年01月10日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Account_Codes-jp.html\n","3. Allocations / 配賦(2020年7月1日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Allocations-jp.html\n","4. Attendees / 同席者(2023年6月28日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Attendees-jp.html\n","5. Audit Rules / 監査ルール(2024年8月17日版)別冊:日付の演算子について => https://la-concur-helper.github.io/concur-docs/Exp_SG_Audit_Rules-jp.html\n","6. Audit Rules (Validation Rules) / 監査ルール（検証ルール）(2022年8月5日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Audit_Rules_Validation_Rules-jp.html\n","7. Budget (Shared) / 予算（製品共通）(2021年2月20日版)別冊:予算管理についてのよくある質問(2019年5月29日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Budget-jp.html\n","8. Car Configuration / 車両設定(2021年1月27日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Car_Config-jp.html\n","9. Cash Advance / 仮払申請(2021年8月27日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Cash_Advance-jp.html\n","10. Central Reconciliation / 突合(2018年4月4日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Central_Recon-jp.html\n","11. Change Log / 変更ログ(2022年4月7日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Config_Chg_Log-jp.html\n","12. Company Billed Statement Reports\n","  (Purchasing Card) / 会社請求の取引明細書レポート（購買カード）(2017年4月4日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Comp_Bill_State-jp.html\n","13. Concept Fields for\n","  Analysis/Intelligence (Shared) / Analysis/Intelligenceの概念フィールド（製品共通）(2016年12月14日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_ConceptFields-jp.html\n","14. Custom Localization Service / カスタム翻訳サービス(2023年3月4日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Custom_Localization_Service_ja.html\n","15. Currency Admin / 通貨管理(2018年4月14日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Currencies-jp.html\n","16. Data Retention (Shared) / データ保持（製品共通）(2024年1月30日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Data_Retention-jp.html\n","17. Delegate Configuration (Shared) / 代理構成（製品共通）(2023年7月18日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Delegate_Config-jp.html\n","18. Email Approval -Policies (ポリシー)のガイドをご参照ください / メール承認-Policies (ポリシー)のガイドをご参照ください => https://la-concur-helper.github.io/concur-docs/Exp_SG_Policies-jp.html\n","19. Email Reminders / メールによる備忘通知(2018年4月4日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Email_Reminders-jp.html\n","20. E-Receipts /  => \n","21. Exceptions / 規定外フラグ(2018年4月4日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Exceptions-jp.html\n","22. Expense Types / 経費タイプ(2024年2月24日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Expense_Types-jp.html\n","23. Feature Hierarchies (Shared) / 機能階層（製品共通）(2018年2月28日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Feat_Hier-jp.html\n","24. File Export Configuration / ファイルエクスポート構成(2016年12月14日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_File_Export_Config-jp.html\n","25. Financial Integration Service\n","  (Shared) / 財務統合サービス(FIS)（製品共通)(2022年1月12日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_FIS-jp.html\n","26. Forms and Fields / フォームとフィールド(2024年8月23日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Forms_Fields-jp.html\n","27. Group Configurations for\n","  Employees (Shared) / 従業員用グループ構成（製品共通）(2022年4月22日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Grp_Config_Emp-jp.html\n","28. Group Configurations for Expense / 経費精算用グループ構成(2023年10月14日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Group_Config-jp.html\n","29. Hotel Auto-Itemization / ホテル自動明細(2021年1月7日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Hotel_AutoItemization-jp.html\n","30. Imaging Settings (Shared) / イメージング設定（製品共通）(2022年11月1日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Imaging_Settings-jp.html\n","31. Japan Public Transportation on\n","  NextGen UI / 新UIでの日本の公共交通機関(2022年8月26日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Japan_Public_Trans_NextGen_UI-jp.html\n","32. Ledgers / 元帳(2015年6月12日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Ledgers-jp.html\n","33. List Management (Shared) / リスト管理（製品共通）(2023年10月14日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_List_Mgmt-jp.html\n","34. Localization (Shared) / 翻訳（製品共通)(2014年2月7日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Localization-jp.html\n","35. Locations (Shared) / 場所（製品共通）(2021年1月28日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Locations-jp.html\n","36. Mileage Service / 走行距離設定(2022年10月12日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Mileage_Service-jp.html\n","37. Password Policy (Shared) / パスワードポリシー（製品共通）(2023年11月15日版) => https://la-concur-helper.github.io/concur-docs/SG_Shr_Password_Policy_Settings-jp.html\n","38. Payment Types / 支払タイプ(2021年12月8日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Payment_Types-jp.html\n","39. PDF and Email Reports /  => \n","40. Personal Credit Card Import /  => \n","41. Policies / ポリシー(2021年3月20日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Policies-jp.html\n","42. Printed Reports Configuration / 印刷用レポート構成(2021年4月17日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Printed_Reports_Config-jp.html\n","43. Receipt Handling - Approved\n","  Senders / 領収書の取扱い-承認済み送信者(2021年1月7日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Rec_Hand_Approved_Senders-jp.html\n","44. Receipt Handling - Faxed Images / 領収書の取扱い-イメージのFAX送信(2015年3月17日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Rec_Hand_Fax-jp.html\n","45. Receipt Handling - Payment Hold\n","  Configuration / 領収書の取扱い-支払保留の構成(2022年9月27日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Rec_Hand_Payment_Hold-jp.html\n","46. Receipt Handling - Receipt Limits / 領収書の取扱い-領収書制限(2018年4月4日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Rec_Hand_Receipt_Limits-jp.html\n","47. Receipt Handling - Scan\n","  Configuration / 領収書の取扱い-スキャン設定(2021年1月7日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Rec_Hand_Scan_Config-jp.html\n","48. Receipt Handling-Digital Receipts (formerly Uploaded and Emailed\n","  Images) / 領収書の取扱い-デジタル領収書(2022年11月3日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Rec_Hand_Digital_Receipts-jp.html\n","49. Reporting Configuration (Shared) / 分析レポート構成（製品共通）(2018年3月26日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Cognos-jp.html\n","50. Role Builder (Shared) / ロールビルダー（製品共通）(2016年12月7日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Role_Builder-jp.html\n","51. SAP Task Center Integration with\n","  Concur Solutions (Shared) / SAP Task Center Integration with\n","  Concur Solutions（製品共通）(2023年2月18日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Task_Center_Integration-jp.html\n","52. Site Settings / サイト設定(2023年3月31日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Site_Settings-jp.html\n","53. Sponsored Guest User /  => \n","54. Single Sign-On Overview (Shared) / シングルサインオン概要（製品共通）(2024年4月8日版) => https://la-concur-helper.github.io/concur-docs/Shr_SSO_Service_Overview-jp.htm\n","55. Single Sign-On (Shared) / シングルサインオン（製品共通）(2022年1月19日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_SSO_Mgmt-jp.htm\n","56. Taxability / Deductibility /  => \n","57. Test User (Shared) / テストユーザー（製品共通）(2024年3月6日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Test_User-jp.html\n","58. Training Administration (Shared) / トレーニング管理（製品共通）(2021年3月19日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Training_Admin-jp.html\n","59. Travel Allowance / 出張手当(2016年12月17日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_TA-jp.html\n","60. Travel Allowance Service / 出張手当サービス-出張手当の設定可能な包括バンドル(2022年4月23日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_TA_ManagedRateService-jp.html\n","61. Validations (Shared) / 検証（製品共通）(2020年8月10日版) => https://la-concur-helper.github.io/concur-docs/Shr_SG_Validations-jp.html\n","62. Travel Segments Payment Types /  => \n","63. Value Added Tax (VAT) / Tax\n","  Administration / 付加価値税/税管理(2018年3月17日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_VAT-jp.html\n","64. Workflow - Authorized Approvers / ワークフロー（承認権限者）(2023年8月25日版) => https://la-concur-helper.github.io/concur-docs/EXP_SG_Workflow_AuthAppr-jp.html\n","65. Workflow - Cost Object Approval / ワークフロー（原価対象の承認者)(2023年8月25日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Workflow_COA-jp.html\n","66. Workflow - General Information / ワークフロー（概要）(2023年10月14日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Workflow_General-jp.html\n","67. Workflow Email Notifications / ワークフロー（メール通知）(2020年3月24日版) => https://la-concur-helper.github.io/concur-docs/Exp_SG_Workflow_Email_Notifications-jp.html\n","\n","どのガイドを処理しますか？(番号): 67\n","\n","選択されたガイド => doc_name=Exp_SG_Workflow_Email_Notifications-jp.docx, base_url=https://la-concur-helper.github.io/concur-docs/Exp_SG_Workflow_Email_Notifications-jp.html\n","[INFO] HTMLソース取得: 長さ=563115\n","[BATCH UPSERT] 18 vectors ...\n","[BATCH RESP]: {'upserted_count': 18}\n","[INFO] 全アップサート完了\n","\n","[INFO] テスト検索: ConcurのAPIでレシート登録したい\n","- ID=Exp_SG_TA_ManagedRateService-jp.docx_chunk4, Score=0.835644245\n","  SectionTitle2: ConcurRequest と財務統合\n","  FullLink: https://la-concur-helper.github.io/concur-docs/Exp_SG_TA_ManagedRateService-jp.html#_Toc108906902\n","  chunk_text: セクション 2\n","ConcurRequest と財務統合\n","\n","Concur Request と財務統合Concur Request もご使用のお客様には、さらに付加 ...\n","\n","- ID=Exp_SG_Car_Config-jp.docx_chunk27, Score=0.830985546\n","  SectionTitle2: 車両の登録\n","  FullLink: https://la-concur-helper.github.io/concur-docs/Exp_SG_Car_Config-jp.html#__RefHeading___Toc66284062\n","  chunk_text: セクション 5\n","車両の登録\n","\n","車両の登録従業員は、プロファイル内の [私有車] または [社用車] のリンクを使用して、自分の車両を登録します。ユーザー管理者は ...\n","\n","- ID=Exp_SG_Car_Config-jp.docx_chunk18, Score=0.83087343\n","  SectionTitle2: 車両の登録\n","  FullLink: https://la-concur-helper.github.io/concur-docs/Exp_SG_Car_Config-jp.html#__RefHeading___Toc66284053\n","  chunk_text: セクション 4\n","車両の登録\n","\n","車両の登録従業員は、プロファイル内の [私有車] または [社用車] のリンクを使用して、自分の車両を登録します。ユーザー管理者は ...\n","\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"IvCSzhxIY_by"}},{"cell_type":"code","source":[],"metadata":{"id":"l9xAcfF8Y8b6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## VectorDB_Embedding2：手元のWORD文書からベクトル化"],"metadata":{"id":"zMuRVvjPZbPq"}},{"cell_type":"code","source":["!pip uninstall -y openai\n","!pip install openai==0.28.0\n","\n","!pip install tiktoken\n","!pip install python-dotenv\n","!pip install pinecone==6.0.1\n","!pip install python-docx\n","\n","import requests\n","import re\n","import os\n","import csv\n","import docx\n","import pandas as pd\n","import time  # ← バッチアップサート時に少し待機するため\n","from urllib.parse import urlsplit\n","from bs4 import BeautifulSoup\n","\n","import openai\n","import tiktoken\n","from dotenv import load_dotenv\n","from pinecone import Pinecone\n","\n","############################\n","# 1) APIキー読み込み\n","############################\n","def load_api_keys(txt_filepath=\"api_keys.txt\"):\n","    if not os.path.exists(txt_filepath):\n","        raise FileNotFoundError(f\"APIキーのファイルが見つかりません: {txt_filepath}\")\n","\n","    with open(txt_filepath, \"r\", encoding=\"utf-8\") as f:\n","        lines = f.readlines()\n","    for line in lines:\n","        line = line.strip()\n","        if not line or line.startswith(\"#\"):\n","            continue\n","        if \"=\" in line:\n","            k, v = line.split(\"=\", 1)\n","            os.environ[k.strip()] = v.strip()\n","\n","load_api_keys(\"api_keys.txt\")\n","\n","PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\", \"\")\n","OPENAI_API_KEY   = os.getenv(\"OPENAI_API_KEY\", \"\")\n","openai.api_key   = OPENAI_API_KEY\n","\n","INDEX_NAME = \"concur-index\"\n","NAMESPACE  = \"demo-html\"\n","\n","############################\n","# 2) Pinecone 初期化\n","############################\n","pc = Pinecone(api_key=PINECONE_API_KEY)\n","index = pc.Index(INDEX_NAME)\n","\n","stats = index.describe_index_stats()\n","ns_info = stats.get(\"namespaces\", {})\n","if NAMESPACE in ns_info:\n","    print(f\"[INFO] namespace '{NAMESPACE}' 既に存在: vector_count={ns_info[NAMESPACE]['vector_count']}\")\n","else:\n","    print(f\"[INFO] namespace '{NAMESPACE}' はまだ存在しません。\")\n","\n","\n","############################\n","# 3) indexページ (HTML) をパース\n","############################\n","def parse_index_page(index_url):\n","    resp = requests.get(index_url)\n","    resp.raise_for_status()\n","    soup = BeautifulSoup(resp.text, \"html.parser\")\n","\n","    result_list = []\n","    table = soup.find(\"table\")\n","    if not table:\n","        print(\"[WARN] テーブルが見つかりません:\", index_url)\n","        return result_list\n","\n","    for row in table.find_all(\"tr\"):\n","        cols = row.find_all(\"td\")\n","        if len(cols) < 4:\n","            continue\n","        guide_en = cols[0].get_text(strip=True)\n","        guide_jp = cols[1].get_text(strip=True)\n","        base_url = cols[3].get_text(strip=True)\n","        result_list.append({\n","            \"GuideNameEn\": guide_en,\n","            \"GuideNameJp\": guide_jp,\n","            \"BaseURL\": base_url\n","        })\n","    return result_list\n","\n","############################\n","# 4) mapping_DB.csv ロード\n","############################\n","def load_mapping_db(csv_path=\"mapping_DB.csv\"):\n","    if not os.path.exists(csv_path):\n","        raise FileNotFoundError(f\"[ERROR] mapping_DB.csv が見つかりません: {csv_path}\")\n","\n","    rows = []\n","    with open(csv_path, \"r\", encoding=\"utf-8-sig\") as f:\n","        reader = csv.DictReader(f, delimiter=\",\")\n","        for row in reader:\n","            rows.append(row)\n","    return rows\n","\n","############################\n","# 5) HTMLソース取得\n","############################\n","def fetch_html(url):\n","    resp = requests.get(url, timeout=10)\n","    resp.raise_for_status()\n","    return resp.text\n","\n","############################\n","# 6) アンカーoffset検索\n","############################\n","def find_anchor_offset(html_src, anchor_id):\n","    pattern = re.compile(\n","        rf'<a[^>]+(?:id|name)\\s*=\\s*[\"\\']{re.escape(anchor_id)}[\"\\']',\n","        re.IGNORECASE\n","    )\n","    m = pattern.search(html_src)\n","    if m:\n","        return m.start()\n","    return -1\n","\n","############################\n","# 7) chunking & embedding\n","############################\n","def get_embedding(text: str, model=\"text-embedding-ada-002\"):\n","    resp = openai.Embedding.create(model=model, input=text)\n","    return resp[\"data\"][0][\"embedding\"]\n","\n","def chunk_text(text: str, chunk_size=2000):\n","    chunks = []\n","    start = 0\n","    length = len(text)\n","    while start < length:\n","        end = min(start + chunk_size, length)\n","        chunks.append(text[start:end])\n","        start = end\n","    return chunks\n","\n","############################\n","# 8) Word文書(ローカル) からテキスト抽出\n","############################\n","def parse_local_word(docx_path):\n","    if not os.path.exists(docx_path):\n","        raise FileNotFoundError(f\"[ERROR] Word文書が見つかりません: {docx_path}\")\n","\n","    doc = docx.Document(docx_path)\n","    paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]\n","    full_text = \"\\n\".join(paragraphs)\n","    return full_text\n","\n","\n","def main():\n","    # 1) indexページからdocリストを取得\n","    index_url = \"https://la-concur-helper.github.io/concur-docs/index.htm\"\n","    docs = parse_index_page(index_url)\n","    if not docs:\n","        print(\"[ERROR] indexページが見つかりません。\")\n","        return\n","\n","    print(\"\\n=== ガイド一覧 ===\")\n","    for i, d in enumerate(docs, start=1):\n","        print(f\"{i}. {d['GuideNameEn']} / {d['GuideNameJp']} => {d['BaseURL']}\")\n","\n","    sel = input(\"\\nどのガイドを処理しますか？(番号): \").strip()\n","    if not sel.isdigit():\n","        print(\"[ERROR] キャンセル or 無効入力\")\n","        return\n","    idx = int(sel)\n","    if idx < 1 or idx > len(docs):\n","        print(\"[ERROR] 範囲外\")\n","        return\n","\n","    chosen = docs[idx-1]\n","    base_url = chosen[\"BaseURL\"]\n","    guide_en = chosen[\"GuideNameEn\"]\n","    guide_jp = chosen[\"GuideNameJp\"]\n","\n","    # 例: \"Exp_SG_Account_Codes-jp.html\" => \"Exp_SG_Account_Codes-jp.docx\"\n","    fname = os.path.basename(urlsplit(base_url).path)\n","    doc_name = re.sub(r\"\\.html?$\", \".docx\", fname, flags=re.IGNORECASE)\n","\n","    print(f\"\\n選択ガイド => doc_name={doc_name}, base_url={base_url}\")\n","\n","    # 2) mapping_DB.csv ロード\n","    mapping_rows = load_mapping_db(\"mapping_DB.csv\")\n","    if not mapping_rows:\n","        print(\"[ERROR] mapping_DB.csv 読み込み失敗\")\n","        return\n","\n","    # doc_name に一致する行\n","    doc_rows = [r for r in mapping_rows if r.get(\"DocName\", \"\") == doc_name]\n","\n","    ############################\n","    # ▼▼ バッチアップサート ▼▼\n","    ############################\n","\n","    # Pineconeアップサート用の設定\n","    BATCH_SIZE = 100\n","    vectors_buffer = []\n","    doc_id_counter = 0\n","\n","    def flush_upsert_buffer():\n","        \"\"\"バッファの内容をまとめてUpsertし、バッファをクリア\"\"\"\n","        nonlocal vectors_buffer\n","        if not vectors_buffer:\n","            return\n","        print(f\"[BATCH UPSERT] {len(vectors_buffer)} vectors ...\")\n","        resp = index.upsert(vectors=vectors_buffer, namespace=NAMESPACE)\n","        print(\"[BATCH RESP]:\", resp)\n","        # バッファをクリア\n","        vectors_buffer = []\n","        # 連打を避けるため少し待機\n","        time.sleep(1)\n","\n","    # ================================\n","    # (A) HTMLダウンロードの試行\n","    # ================================\n","    can_download = True\n","    html_src = \"\"\n","    try:\n","        print(f\"[INFO] ダウンロード試行: {base_url}\")\n","        html_src = fetch_html(base_url)\n","    except Exception as e:\n","        print(f\"[WARN] ダウンロード失敗: {e}\")\n","        can_download = False\n","\n","    if can_download and doc_rows:\n","        # --- HTMLが成功ダウンロード → mapping_DBに従い、アンカー単位で分割 ---\n","        print(\"[INFO] Webダウンロード成功 → mapping_DBに従い、アンカー単位で分割します。\")\n","\n","        # PageNumber + AnchorID でソート\n","        def sort_key(r):\n","            p = 999999\n","            if r[\"PageNumber\"].isdigit():\n","                p = int(r[\"PageNumber\"])\n","            return (p, r[\"AnchorID\"])\n","        sorted_rows = sorted(doc_rows, key=sort_key)\n","\n","        offsets = []\n","        for row in sorted_rows:\n","            anchor_id = row[\"AnchorID\"]\n","            off = find_anchor_offset(html_src, anchor_id)\n","            offsets.append({\"row\": row, \"offset\": off})\n","\n","        for i in range(len(offsets)):\n","            cur = offsets[i]\n","            r   = cur[\"row\"]\n","            off_i = cur[\"offset\"]\n","            if off_i < 0:\n","                off_i = 0\n","\n","            if i < len(offsets)-1:\n","                off_j = offsets[i+1][\"offset\"]\n","                if off_j < 0:\n","                    off_j = len(html_src)\n","            else:\n","                off_j = len(html_src)\n","            if off_j < off_i:\n","                off_j = off_i\n","\n","            raw_segment = html_src[off_i:off_j]\n","            text_str = re.sub(r\"<[^>]+>\", \"\", raw_segment)\n","            text_str = re.sub(r\"\\s+\", \" \", text_str).strip()\n","            if not text_str:\n","                continue\n","\n","            chunk_list = chunk_text(text_str, chunk_size=2000)\n","\n","            doc_name_val = r[\"DocName\"]\n","            guide_jp_val = r[\"GuideNameJp\"]\n","            sec1         = r[\"SectionTitle1\"]\n","            sec2         = r[\"SectionTitle2\"]\n","            anchor_val   = r[\"AnchorID\"]\n","            link_val     = r[\"FullLink\"]\n","\n","            for chunk_str_data in chunk_list:\n","                doc_id_counter += 1\n","                chunk_id = f\"{doc_name_val}_chunk{doc_id_counter}\"\n","\n","                emb = get_embedding(chunk_str_data)\n","                meta = {\n","                    \"DocName\": doc_name_val,\n","                    \"GuideNameJp\": guide_jp_val,\n","                    \"SectionTitle1\": sec1,\n","                    \"SectionTitle2\": sec2,\n","                    \"AnchorID\": anchor_val,\n","                    \"FullLink\": link_val,\n","                    \"chunk_text\": chunk_str_data\n","                }\n","\n","                vectors_buffer.append({\n","                    \"id\": chunk_id,\n","                    \"values\": emb,\n","                    \"metadata\": meta\n","                })\n","\n","                # バッファが一定サイズに達したらUpsert\n","                if len(vectors_buffer) >= BATCH_SIZE:\n","                    flush_upsert_buffer()\n","\n","        # ループ完了後、残りがあればフラッシュ\n","        flush_upsert_buffer()\n","        print(\"[INFO] HTML文書のアップサート完了.\")\n","\n","    else:\n","        # ================================\n","        # (B) Word文書がローカルにあるパターン\n","        # ================================\n","        print(\"\\n[INFO] Word文書のローカルアップロード対応に切り替えます。\")\n","        local_path = input(\"Word文書 (.docx) のローカルファイルパスを入力してください: \").strip()\n","        if not os.path.exists(local_path):\n","            print(f\"[ERROR] 指定ファイルが見つかりません: {local_path}\")\n","            return\n","\n","        # parse_local_word でテキスト全抽出\n","        full_text = parse_local_word(local_path)\n","        print(f\"[INFO] Word文書の段落合計文字数={len(full_text)}\")\n","\n","        # chunk化 & Embedding\n","        chunked_data = chunk_text(full_text, chunk_size=2000)\n","\n","        doc_name_val = doc_name\n","        guide_jp_val = guide_jp\n","\n","        for chunk_str_data in chunked_data:\n","            doc_id_counter += 1\n","            chunk_id = f\"{doc_name_val}_chunk{doc_id_counter}\"\n","\n","            emb = get_embedding(chunk_str_data)\n","            meta = {\n","                \"DocName\": doc_name_val,\n","                \"GuideNameJp\": guide_jp_val,\n","                \"FullLink\": \"(Local file, no link)\",\n","                \"chunk_text\": chunk_str_data\n","            }\n","            vectors_buffer.append({\n","                \"id\": chunk_id,\n","                \"values\": emb,\n","                \"metadata\": meta\n","            })\n","\n","            # バッファが一定サイズに達したらUpsert\n","            if len(vectors_buffer) >= BATCH_SIZE:\n","                flush_upsert_buffer()\n","\n","        # ループ完了後、残りがあればフラッシュ\n","        flush_upsert_buffer()\n","        print(\"[INFO] ローカルWord文書のアップサート完了.\")\n","\n","    # テスト検索\n","    test_query = \"ConcurのAPIでレシート登録したい\"\n","    print(f\"\\n[INFO] テスト検索: {test_query}\")\n","    q_emb = get_embedding(test_query)\n","    sr = index.query(\n","        vector=q_emb,\n","        top_k=3,\n","        include_metadata=True,\n","        namespace=NAMESPACE\n","    )\n","    for match in sr.matches:\n","        md = match.metadata\n","        print(f\"- ID={match.id}, Score={match.score}\")\n","        print(\"  DocName:\", md.get(\"DocName\"))\n","        print(\"  chunk_text:\", md.get(\"chunk_text\",\"\")[:80], \"...\")\n","        print(\"\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"boXKeWJ8Y9Co","outputId":"40f68431-d094-4d58-e49d-97c08b1cc7e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: openai 0.28.0\n","Uninstalling openai-0.28.0:\n","  Successfully uninstalled openai-0.28.0\n","Collecting openai==0.28.0\n","  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (4.67.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (3.11.13)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (2025.1.31)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.18.3)\n","Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n","Installing collected packages: openai\n","Successfully installed openai-0.28.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["openai"]},"id":"8cd35ca833fe47bebe343b4aed860a3d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n","Requirement already satisfied: pinecone==6.0.1 in /usr/local/lib/python3.11/dist-packages (6.0.1)\n","Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone==6.0.1) (2025.1.31)\n","Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone==6.0.1) (0.0.7)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone==6.0.1) (2.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone==6.0.1) (4.12.2)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone==6.0.1) (2.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone==6.0.1) (1.17.0)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m^C\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"APIキーのファイルが見つかりません: api_keys.txt","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-fc8ebb100e01>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mload_api_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"api_keys.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mPINECONE_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PINECONE_API_KEY\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-fc8ebb100e01>\u001b[0m in \u001b[0;36mload_api_keys\u001b[0;34m(txt_filepath)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_api_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"api_keys.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"APIキーのファイルが見つかりません: {txt_filepath}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: APIキーのファイルが見つかりません: api_keys.txt"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}